{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIG =====\n",
    "DOMAIN = \"money-heist\"     # change only this\n",
    "\n",
    "TOP_K = 20      # candidates returned from FAISS\n",
    "TOP_FINAL = 5   # after reranker (top-N to show)\n",
    "# ==================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import textwrap\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "import faiss\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "except ImportError:\n",
    "    SentenceTransformer = None\n",
    "    CrossEncoder = None\n",
    "    print(\"⚠️ sentence-transformers not installed. Free-form queries or reranker may fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: /data/sundeep/Fandom_SI/data/embeddings/spans_money-heist.npy True\n",
      "IDs: /data/sundeep/Fandom_SI/data/embeddings/spans_money-heist.index_ids.npy True\n",
      "Spans CSV: /data/sundeep/Fandom_SI/data/processed/spans_money-heist.csv True\n",
      "FAISS: /data/sundeep/Fandom_SI/data/indexes/faiss_flat_money-heist.index True\n",
      "RERANKER_ROOT: /data/sundeep/Fandom_SI/models/reranker/money-heist True\n"
     ]
    }
   ],
   "source": [
    "REPO_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "EMB_DIR = DATA_DIR / \"embeddings\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "INDEX_DIR = DATA_DIR / \"indexes\"\n",
    "MODEL_DIR = REPO_ROOT / \"models\"\n",
    "\n",
    "EMB_PATH   = EMB_DIR  / f\"spans_{DOMAIN}.npy\"\n",
    "ID_PATH    = EMB_DIR  / f\"spans_{DOMAIN}.index_ids.npy\"\n",
    "SPANS_PATH = PROC_DIR / f\"spans_{DOMAIN}.csv\"\n",
    "FAISS_PATH = INDEX_DIR / f\"faiss_flat_{DOMAIN}.index\"   # adjust name if needed\n",
    "\n",
    "RERANKER_ROOT = MODEL_DIR / \"reranker\" / DOMAIN   # e.g. models/reranker/money-heist\n",
    "\n",
    "print(\"Embeddings:\", EMB_PATH, EMB_PATH.exists())\n",
    "print(\"IDs:\",       ID_PATH, ID_PATH.exists())\n",
    "print(\"Spans CSV:\", SPANS_PATH, SPANS_PATH.exists())\n",
    "print(\"FAISS:\",     FAISS_PATH, FAISS_PATH.exists())\n",
    "print(\"RERANKER_ROOT:\", RERANKER_ROOT, RERANKER_ROOT.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using reranker dir: /data/sundeep/Fandom_SI/models/reranker/money-heist/best\n"
     ]
    }
   ],
   "source": [
    "def find_reranker_dir(root: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Return the first subdirectory under root that looks like a HF model\n",
    "    (has config.json). Prefer a folder named 'best' if it exists.\n",
    "    \"\"\"\n",
    "    if not root.exists():\n",
    "        raise ValueError(f\"RERANKER_ROOT does not exist: {root}\")\n",
    "\n",
    "    # 1) Prefer '<root>/best'\n",
    "    best_dir = root / \"best\"\n",
    "    if (best_dir / \"config.json\").exists():\n",
    "        print(\"Using reranker dir:\", best_dir)\n",
    "        return best_dir\n",
    "\n",
    "    # 2) Otherwise search all subdirs for config.json\n",
    "    candidates = []\n",
    "    for sub in root.iterdir():\n",
    "        if sub.is_dir() and (sub / \"config.json\").exists():\n",
    "            candidates.append(sub)\n",
    "\n",
    "    if not candidates:\n",
    "        raise ValueError(f\"No HF model (config.json) found under {root}\")\n",
    "\n",
    "    # Just take the first one for now\n",
    "    print(\"Using reranker dir:\", candidates[0])\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "RERANKER_DIR = find_reranker_dir(RERANKER_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (3189, 384)\n",
      "Index_ids shape : (3189,)\n",
      "Spans rows: 3189\n",
      "Spans columns: ['span_id', 'article_id', 'page_name', 'title', 'section', 'span_index', 'start_char', 'end_char', 'len_chars', 'num_sents', 'text', 'url', 'source_path']\n",
      "IDs in index_ids but not in spans.csv: 0\n",
      "Example missing: []\n"
     ]
    }
   ],
   "source": [
    "# embeddings + ids\n",
    "embeddings = np.load(EMB_PATH)\n",
    "index_ids  = np.load(ID_PATH, allow_pickle=True).astype(str)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Index_ids shape :\", index_ids.shape)\n",
    "\n",
    "# spans\n",
    "df_spans = pd.read_csv(SPANS_PATH)\n",
    "df_spans[\"span_id\"] = df_spans[\"span_id\"].astype(str)\n",
    "\n",
    "print(\"Spans rows:\", len(df_spans))\n",
    "print(\"Spans columns:\", df_spans.columns.tolist())\n",
    "\n",
    "assert \"text\" in df_spans.columns, \"Expected span text column 'text' in spans CSV.\"\n",
    "\n",
    "# span_id -> row\n",
    "spanid_to_row = {sid: i for i, sid in enumerate(df_spans[\"span_id\"].tolist())}\n",
    "\n",
    "missing = [sid for sid in index_ids if sid not in spanid_to_row]\n",
    "print(\"IDs in index_ids but not in spans.csv:\", len(missing))\n",
    "print(\"Example missing:\", missing[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query encoder model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Encoder loaded.\n"
     ]
    }
   ],
   "source": [
    "MODEL_INFO_PATH = EMB_DIR / f\"model_info_{DOMAIN}.json\"\n",
    "\n",
    "if MODEL_INFO_PATH.exists():\n",
    "    with MODEL_INFO_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        model_info = json.load(f)\n",
    "    encoder_name = model_info.get(\"model_name\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "else:\n",
    "    encoder_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "print(\"Query encoder model:\", encoder_name)\n",
    "encoder = SentenceTransformer(encoder_name)\n",
    "print(\"Encoder loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index: /data/sundeep/Fandom_SI/data/indexes/faiss_flat_money-heist.index\n",
      "Index dimension: 384\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "print(\"FAISS index:\", FAISS_PATH)\n",
    "print(\"Index dimension:\", index.d)\n",
    "\n",
    "# make sure embeddings are float32 for FAISS\n",
    "if embeddings.dtype != np.float32:\n",
    "    embeddings = embeddings.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_text(span_id: str):\n",
    "    idx = spanid_to_row.get(span_id)\n",
    "    if idx is None:\n",
    "        return None\n",
    "    return str(df_spans.iloc[idx][\"text\"])\n",
    "\n",
    "\n",
    "def encode_query_text(text: str) -> np.ndarray:\n",
    "    vec = encoder.encode([text], convert_to_numpy=True)\n",
    "    if vec.dtype != np.float32:\n",
    "        vec = vec.astype(\"float32\")\n",
    "    return vec\n",
    "\n",
    "\n",
    "def faiss_search(query_vec: np.ndarray, top_k: int = TOP_K):\n",
    "    if query_vec.ndim == 1:\n",
    "        query_vec = query_vec[None, :]\n",
    "    if query_vec.dtype != np.float32:\n",
    "        query_vec = query_vec.astype(\"float32\")\n",
    "\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    D, I = D[0], I[0]\n",
    "\n",
    "    results = []\n",
    "    for rank, (dist, idx) in enumerate(zip(D, I)):\n",
    "        if idx < 0:\n",
    "            continue\n",
    "        span_id = index_ids[idx]\n",
    "        results.append({\n",
    "            \"rank\": rank,\n",
    "            \"faiss_score\": float(dist),\n",
    "            \"array_idx\": int(idx),\n",
    "            \"span_id\": span_id,\n",
    "            \"text\": get_span_text(span_id),\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def rerank_results(query_text: str, candidates):\n",
    "    # candidate[\"text\"] already has span text\n",
    "    pairs = [(query_text, c[\"text\"] or \"\") for c in candidates]\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    for c, s in zip(candidates, scores):\n",
    "        c[\"rerank_score\"] = float(s)\n",
    "\n",
    "    # sort by reranker score descending (higher = more relevant)\n",
    "    return sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "\n",
    "def pretty_block(title: str):\n",
    "    print(\"\\n\" + \"=\"*30 + f\" {title} \" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "\n",
    "def show_results(results, score_key: str, top_n: int = TOP_FINAL):\n",
    "    for r in results[:top_n]:\n",
    "        print(f\"[rank {r['rank']}] span_id={r['span_id']} {score_key}={r[score_key]:.4f}\")\n",
    "        print(textwrap.fill((r[\"text\"] or \"\").replace(\"\\n\", \" \"), width=110))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(query_text: str):\n",
    "    pretty_block(\"QUERY\")\n",
    "    print(query_text)\n",
    "\n",
    "    # bi-encoder → FAISS\n",
    "    q_vec = encode_query_text(query_text)\n",
    "    faiss_results = faiss_search(q_vec, top_k=TOP_K)\n",
    "\n",
    "    pretty_block(\"BEFORE RERANKER (FAISS top-k)\")\n",
    "    show_results(faiss_results, score_key=\"faiss_score\", top_n=TOP_FINAL)\n",
    "\n",
    "    # rerank same candidates\n",
    "    reranked = rerank_results(query_text, faiss_results)\n",
    "\n",
    "    pretty_block(\"AFTER RERANKER (CrossEncoder top-k)\")\n",
    "    show_results(reranked, score_key=\"rerank_score\", top_n=TOP_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== QUERY ==============================\n",
      "\n",
      "What was the Professor's main plan in the first heist?\n",
      "\n",
      "============================== BEFORE RERANKER (FAISS top-k) ==============================\n",
      "\n",
      "[rank 0] span_id=money-heist_span_0002949 faiss_score=0.6567\n",
      "The Professor teaches the robbers everything they need to know about the heist in that room.\n",
      "\n",
      "[rank 1] span_id=money-heist_span_0002904 faiss_score=0.6567\n",
      "The Professor teaches the robbers everything they need to know about the heist in that room.\n",
      "\n",
      "[rank 2] span_id=money-heist_span_0002850 faiss_score=0.6516\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "[rank 3] span_id=money-heist_span_0002507 faiss_score=0.6516\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "[rank 4] span_id=money-heist_span_0002478 faiss_score=0.6516\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "\n",
      "============================== AFTER RERANKER (CrossEncoder top-k) ==============================\n",
      "\n",
      "[rank 2] span_id=money-heist_span_0002850 rerank_score=0.8829\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "[rank 3] span_id=money-heist_span_0002507 rerank_score=0.8829\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "[rank 4] span_id=money-heist_span_0002478 rerank_score=0.8829\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "[rank 5] span_id=money-heist_span_0002287 rerank_score=0.8829\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n",
      "[rank 6] span_id=money-heist_span_0002587 rerank_score=0.8829\n",
      "The Professor led a second heist in the Bank of Spain , in an effort to pressure the Spanish government who\n",
      "had arrested Rio . This was a heist that he and his half-brother Berlin had planned years ago.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare(\"What was the Professor's main plan in the first heist?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k_for_ranking(ranked_ids, gold_ids, k=10):\n",
    "    \"\"\"\n",
    "    Simple NDCG@k where gold_ids are relevant (binary relevance).\n",
    "    \"\"\"\n",
    "    gold_set = set(gold_ids)\n",
    "    topk = ranked_ids[:k]\n",
    "    rels = np.array([1 if sid in gold_set else 0 for sid in topk], dtype=np.float32)\n",
    "\n",
    "    if rels.sum() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # DCG\n",
    "    dcg = np.sum(rels / np.log2(np.arange(len(rels), dtype=np.float32) + 2.0))\n",
    "    # IDCG: best case is putting a single relevant at rank 1\n",
    "    idcg = 1.0\n",
    "    return float(dcg / idcg)\n",
    "\n",
    "\n",
    "def evaluate_reranker_on_dev(max_queries=200, ks=(1, 5, 10)):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval quality using span_identifier_dev.jsonl\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "        - Global MRR and Recall@k for FAISS vs RERANK\n",
    "        - Global NDCG@10 for FAISS vs RERANK\n",
    "        - Also prints coverage@TOP_K and conditional metrics given coverage\n",
    "    \"\"\"\n",
    "    eval_subset = eval_queries[:max_queries]\n",
    "\n",
    "    faiss_rr_sum = 0.0\n",
    "    rerank_rr_sum = 0.0\n",
    "    faiss_hits_sum = {k: 0.0 for k in ks}\n",
    "    rerank_hits_sum = {k: 0.0 for k in ks}\n",
    "    faiss_ndcg10_sum = 0.0\n",
    "    rerank_ndcg10_sum = 0.0\n",
    "\n",
    "    # For coverage and conditional metrics (only queries where FAISS retrieved the gold somewhere in TOP_K)\n",
    "    covered = 0\n",
    "    faiss_rr_covered = 0.0\n",
    "    rerank_rr_covered = 0.0\n",
    "    faiss_hits_covered = {k: 0.0 for k in ks}\n",
    "    rerank_hits_covered = {k: 0.0 for k in ks}\n",
    "    faiss_ndcg10_covered = 0.0\n",
    "    rerank_ndcg10_covered = 0.0\n",
    "\n",
    "    used = 0\n",
    "\n",
    "    for q in eval_subset:\n",
    "        qid = q[\"query_id\"]\n",
    "        text = q[\"text\"]\n",
    "\n",
    "        if qid not in gold_by_qid:\n",
    "            continue\n",
    "\n",
    "        gold_ids = gold_by_qid[qid]\n",
    "        gold_set = set(gold_ids)\n",
    "\n",
    "        # Encode query\n",
    "        q_vec = encode_query_text(text)\n",
    "\n",
    "        # --- FAISS-only ranking ---\n",
    "        faiss_results = faiss_search(q_vec, top_k=TOP_K)\n",
    "        faiss_ranked_ids = [r[\"span_id\"] for r in faiss_results]\n",
    "\n",
    "        # --- FAISS + Reranker ranking ---\n",
    "        reranked = rerank_results(text, faiss_results)\n",
    "        rerank_ranked_ids = [r[\"span_id\"] for r in reranked]\n",
    "\n",
    "        # Global MRR + Recall@k\n",
    "        faiss_rr, faiss_hits = metrics_for_ranking(faiss_ranked_ids, gold_ids, ks)\n",
    "        rerank_rr, rerank_hits = metrics_for_ranking(rerank_ranked_ids, gold_ids, ks)\n",
    "\n",
    "        # Global NDCG@10\n",
    "        faiss_ndcg10 = ndcg_at_k_for_ranking(faiss_ranked_ids, gold_ids, k=10)\n",
    "        rerank_ndcg10 = ndcg_at_k_for_ranking(rerank_ranked_ids, gold_ids, k=10)\n",
    "\n",
    "        faiss_rr_sum += faiss_rr\n",
    "        rerank_rr_sum += rerank_rr\n",
    "        faiss_ndcg10_sum += faiss_ndcg10\n",
    "        rerank_ndcg10_sum += rerank_ndcg10\n",
    "\n",
    "        for k in ks:\n",
    "            faiss_hits_sum[k] += faiss_hits[k]\n",
    "            rerank_hits_sum[k] += rerank_hits[k]\n",
    "\n",
    "        # Coverage + conditional metrics (only if FAISS retrieved the gold somewhere in TOP_K)\n",
    "        if any(sid in gold_set for sid in faiss_ranked_ids):\n",
    "            covered += 1\n",
    "            faiss_rr_covered += faiss_rr\n",
    "            rerank_rr_covered += rerank_rr\n",
    "            faiss_ndcg10_covered += faiss_ndcg10\n",
    "            rerank_ndcg10_covered += rerank_ndcg10\n",
    "\n",
    "            for k in ks:\n",
    "                faiss_hits_covered[k] += faiss_hits[k]\n",
    "                rerank_hits_covered[k] += rerank_hits[k]\n",
    "\n",
    "        used += 1\n",
    "\n",
    "    if used == 0:\n",
    "        print(\"No queries with gold labels found.\")\n",
    "        return None\n",
    "\n",
    "    # ---------- Global metrics ----------\n",
    "    faiss_mrr = faiss_rr_sum / used\n",
    "    rerank_mrr = rerank_rr_sum / used\n",
    "\n",
    "    faiss_recall = {k: faiss_hits_sum[k] / used for k in ks}\n",
    "    rerank_recall = {k: rerank_hits_sum[k] / used for k in ks}\n",
    "\n",
    "    faiss_ndcg10_mean = faiss_ndcg10_sum / used\n",
    "    rerank_ndcg10_mean = rerank_ndcg10_sum / used\n",
    "\n",
    "    rows = []\n",
    "    rows.append({\n",
    "        \"metric\": \"MRR@TOP_K (global)\",\n",
    "        \"faiss\": faiss_mrr,\n",
    "        \"rerank\": rerank_mrr,\n",
    "    })\n",
    "    for k in ks:\n",
    "        rows.append({\n",
    "            \"metric\": f\"Recall@{k} (global)\",\n",
    "            \"faiss\": faiss_recall[k],\n",
    "            \"rerank\": rerank_recall[k],\n",
    "        })\n",
    "    rows.append({\n",
    "        \"metric\": \"NDCG@10 (global)\",\n",
    "        \"faiss\": faiss_ndcg10_mean,\n",
    "        \"rerank\": rerank_ndcg10_mean,\n",
    "    })\n",
    "\n",
    "    # ---------- Coverage & conditional metrics ----------\n",
    "    coverage = covered / used\n",
    "    print(f\"Evaluated on {used} queries.\")\n",
    "    print(f\"FAISS coverage@TOP_K (gold present in top-{TOP_K}): {coverage:.4f}\")\n",
    "\n",
    "    if covered > 0:\n",
    "        faiss_mrr_cond = faiss_rr_covered / covered\n",
    "        rerank_mrr_cond = rerank_rr_covered / covered\n",
    "\n",
    "        faiss_recall_cond = {k: faiss_hits_covered[k] / covered for k in ks}\n",
    "        rerank_recall_cond = {k: rerank_hits_covered[k] / covered for k in ks}\n",
    "\n",
    "        faiss_ndcg10_cond = faiss_ndcg10_covered / covered\n",
    "        rerank_ndcg10_cond = rerank_ndcg10_covered / covered\n",
    "\n",
    "        print(\"\\nConditional metrics (only queries where FAISS retrieved the gold somewhere in TOP_K):\")\n",
    "        print(f\"  FAISS  MRR@TOP_K: {faiss_mrr_cond:.4f}\")\n",
    "        print(f\"  RERANK MRR@TOP_K: {rerank_mrr_cond:.4f}\")\n",
    "        for k in ks:\n",
    "            print(f\"  Recall@{k}: FAISS={faiss_recall_cond[k]:.4f}, RERANK={rerank_recall_cond[k]:.4f}\")\n",
    "        print(f\"  NDCG@10: FAISS={faiss_ndcg10_cond:.4f}, RERANK={rerank_ndcg10_cond:.4f}\")\n",
    "\n",
    "        rows.append({\n",
    "            \"metric\": \"MRR@TOP_K (conditional)\",\n",
    "            \"faiss\": faiss_mrr_cond,\n",
    "            \"rerank\": rerank_mrr_cond,\n",
    "        })\n",
    "        for k in ks:\n",
    "            rows.append({\n",
    "                \"metric\": f\"Recall@{k} (conditional)\",\n",
    "                \"faiss\": faiss_recall_cond[k],\n",
    "                \"rerank\": rerank_recall_cond[k],\n",
    "            })\n",
    "        rows.append({\n",
    "            \"metric\": \"NDCG@10 (conditional)\",\n",
    "            \"faiss\": faiss_ndcg10_cond,\n",
    "            \"rerank\": rerank_ndcg10_cond,\n",
    "        })\n",
    "\n",
    "    df_metrics = pd.DataFrame(rows)\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 159 queries.\n",
      "FAISS coverage@TOP_K (gold present in top-20): 0.3082\n",
      "\n",
      "Conditional metrics (only queries where FAISS retrieved the gold somewhere in TOP_K):\n",
      "  FAISS  MRR@TOP_K: 0.4074\n",
      "  RERANK MRR@TOP_K: 0.5683\n",
      "  Recall@1: FAISS=0.2449, RERANK=0.4082\n",
      "  Recall@5: FAISS=0.5918, RERANK=0.7755\n",
      "  Recall@10: FAISS=0.8163, RERANK=0.9184\n",
      "  NDCG@10: FAISS=0.4935, RERANK=0.6474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>faiss</th>\n",
       "      <th>rerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MRR@TOP_K (global)</td>\n",
       "      <td>0.125554</td>\n",
       "      <td>0.175140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall@1 (global)</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.125786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall@5 (global)</td>\n",
       "      <td>0.182390</td>\n",
       "      <td>0.238994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall@10 (global)</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>0.283019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDCG@10 (global)</td>\n",
       "      <td>0.152096</td>\n",
       "      <td>0.199502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MRR@TOP_K (conditional)</td>\n",
       "      <td>0.407408</td>\n",
       "      <td>0.568312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall@1 (conditional)</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall@5 (conditional)</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recall@10 (conditional)</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NDCG@10 (conditional)</td>\n",
       "      <td>0.493537</td>\n",
       "      <td>0.647365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    metric     faiss    rerank\n",
       "0       MRR@TOP_K (global)  0.125554  0.175140\n",
       "1        Recall@1 (global)  0.075472  0.125786\n",
       "2        Recall@5 (global)  0.182390  0.238994\n",
       "3       Recall@10 (global)  0.251572  0.283019\n",
       "4         NDCG@10 (global)  0.152096  0.199502\n",
       "5  MRR@TOP_K (conditional)  0.407408  0.568312\n",
       "6   Recall@1 (conditional)  0.244898  0.408163\n",
       "7   Recall@5 (conditional)  0.591837  0.775510\n",
       "8  Recall@10 (conditional)  0.816327  0.918367\n",
       "9    NDCG@10 (conditional)  0.493537  0.647365"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = evaluate_reranker_on_dev(max_queries=200, ks=(1, 5, 10))\n",
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fandom-span",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
